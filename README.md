# üéôÔ∏è Flutter Voice Bridge

**Flutter Voice Bridge** is a **production-ready** cross-platform application showcasing advanced integration of native device features and local AI capabilities within a Flutter app. It provides a robust foundation for building voice-powered applications, featuring audio recording, playback, and **fully working offline speech-to-text transcription** using `Whisper.cpp` with GPU acceleration.

This project follows **Clean Architecture** principles and demonstrates **real-world implementation** of complex Flutter concepts including FFI, Platform Channels, and AI integration.

> **üéØ Status**: **PRODUCTION READY** - Full iOS/macOS transcription with GPU acceleration working perfectly. Android audio recording fully functional.

## ‚ú® Features

- **‚úÖ Cross-Platform Audio Recording**: High-quality audio capture on iOS, macOS, and Android with optimized formats (WAV 16kHz).
- **‚úÖ Local Audio Playback**: Play recorded memos directly within the app across all platforms.
- **‚úÖ Offline Speech-to-Text**: **FULLY WORKING** on-device transcription using `Whisper.cpp` via Dart FFI with Metal GPU acceleration on Apple Silicon.
- **‚úÖ Real-time Audio Visualization**: Custom waveform, spectrum, and particle visualizations during recording.
- **‚úÖ Keyword Extraction**: Automatic keyword detection from transcribed text with intelligent filtering.
- **‚úÖ Clean Architecture (MVVM)**: A clear separation of concerns between UI, business logic, and data layers.
- **‚úÖ Dependency Injection**: Loose coupling and enhanced testability using `get_it`.
- **‚úÖ State Management with BLoC/Cubit**: Predictable and scalable state management with real-time UI updates.
- **‚úÖ Native Integration**: Deep integration with native APIs via Platform Channels and Dart FFI.
- **‚úÖ GPU Acceleration**: Metal GPU support on Apple Silicon (M1/M2/M3) for fast AI inference.
- **‚úÖ Native Platform Views**: Custom native UI components integrated seamlessly with Flutter.
- **üìö Comprehensive Documentation**: Complete guides for architecture, setup, and feature implementation.

## üèõÔ∏è Project Architecture

The application is structured using a clean, layered architecture that separates concerns and promotes modularity.

### üìä System Architecture Overview

```mermaid
graph TB
    %% Flutter App Architecture & Native Connections
    subgraph "Flutter Layer"
        UI["`**UI Layer**<br/>
        ‚Ä¢ HomeView (BlocConsumer)<br/>
        ‚Ä¢ VoiceRecorderButton<br/>
        ‚Ä¢ AudioVisualizer<br/>
        ‚Ä¢ NativeTextView (Platform View)`"]
        
        BL["`**Business Logic**<br/>
        ‚Ä¢ HomeCubit (State Management)<br/>
        ‚Ä¢ Recording/Transcription Logic<br/>
        ‚Ä¢ Error Handling`"]
        
        Data["`**Data Layer**<br/>
        ‚Ä¢ VoiceMemoService<br/>
        ‚Ä¢ VoiceMemo Model<br/>
        ‚Ä¢ File I/O Operations`"]
    end
    
    subgraph "Platform Interface"
        PC["`**Platform Channels**<br/>
        ‚Ä¢ Audio Recording Control<br/>
        ‚Ä¢ Permission Management<br/>
        ‚Ä¢ Platform View Integration`"]
        
        FFI["`**Dart FFI**<br/>
        ‚Ä¢ Direct C++ Integration<br/>
        ‚Ä¢ Whisper.cpp Binding<br/>
        ‚Ä¢ Memory Management`"]
    end
    
    subgraph "iOS/macOS Native"
        iOS_Swift["`**Swift Implementation**<br/>
        ‚Ä¢ AVAudioRecorder<br/>
        ‚Ä¢ Audio Session Config<br/>
        ‚Ä¢ WAV Format (16kHz)`"]
        
        iOS_Metal["`**Metal GPU**<br/>
        ‚Ä¢ Hardware Acceleration<br/>
        ‚Ä¢ Neural Network Ops<br/>
        ‚Ä¢ Apple M1/M2/M3 Support`"]
    end
    
    subgraph "Android Native"
        Android_Kotlin["`**Kotlin Implementation**<br/>
        ‚Ä¢ MediaRecorder<br/>
        ‚Ä¢ Audio Permissions<br/>
        ‚Ä¢ WAV Format`"]
        
        Android_GPU["`**GPU Support**<br/>
        ‚Ä¢ OpenGL/Vulkan<br/>
        ‚Ä¢ Compute Shaders`"]
    end
    
    subgraph "AI Processing Layer"
        Whisper["`**Whisper.cpp**<br/>
        ‚Ä¢ OpenAI Whisper Model<br/>
        ‚Ä¢ GGML Backend<br/>
        ‚Ä¢ 147MB Base Model<br/>
        ‚Ä¢ Real-time Processing`"]
        
        Models["`**AI Models**<br/>
        ‚Ä¢ ggml-base.en.bin<br/>
        ‚Ä¢ English Language Support<br/>
        ‚Ä¢ Offline Inference`"]
    end
    
    %% Flutter Internal Flow
    UI --> BL
    BL --> Data
    BL --> PC
    BL --> FFI
    
    %% Platform Channel Connections
    PC --> iOS_Swift
    PC --> Android_Kotlin
    
    %% FFI Direct Connections
    FFI --> Whisper
    Whisper --> Models
    
    %% GPU Acceleration Paths
    iOS_Swift --> iOS_Metal
    Android_Kotlin --> Android_GPU
    Whisper --> iOS_Metal
    Whisper --> Android_GPU
    
    %% Styling
    classDef flutter fill:#1e3a8a,stroke:#3b82f6,stroke-width:2px,color:#ffffff
    classDef platform fill:#581c87,stroke:#a855f7,stroke-width:2px,color:#ffffff
    classDef native fill:#14532d,stroke:#22c55e,stroke-width:2px,color:#ffffff
    classDef ai fill:#9a3412,stroke:#f97316,stroke-width:2px,color:#ffffff
    
    class UI,BL,Data flutter
    class PC,FFI platform
    class iOS_Swift,Android_Kotlin,iOS_Metal,Android_GPU native
    class Whisper,Models ai
```

### üîÑ Recording & Transcription Flow

```mermaid
sequenceDiagram
    participant User
    participant UI as Flutter UI
    participant Cubit as HomeCubit
    participant AudioSvc as AudioService
    participant PC as Platform Channel
    participant Native as Native Layer
    participant FFI as Dart FFI
    participant Whisper as Whisper.cpp
    participant GPU as Metal GPU
    participant FS as File System
    
    Note over User,FS: üé§ Complete Voice Recording & AI Transcription Pipeline
    
    User->>UI: Tap Record Button
    UI->>Cubit: startRecording()
    
    activate Cubit
    Cubit->>AudioSvc: startRecording()
    AudioSvc->>PC: invokeMethod('startRecording')
    
    PC->>Native: Platform-specific audio setup
    alt iOS/macOS
        Native->>Native: AVAudioRecorder.record()
        Note right of Native: 16kHz WAV format for Whisper
    else Android
        Native->>Native: MediaRecorder.start()
        Note right of Native: 16kHz WAV format
    end
    
    Native-->>PC: Recording started
    PC-->>AudioSvc: Success response
    AudioSvc-->>Cubit: Recording active
    Cubit-->>UI: RecordingInProgress state
    UI-->>User: Show waveform animation
    
    Note over User,FS: üéµ Recording in progress...
    
    User->>UI: Tap Stop Button
    UI->>Cubit: stopRecording()
    Cubit->>AudioSvc: stopRecording()
    AudioSvc->>PC: invokeMethod('stopRecording')
    
    PC->>Native: Stop recording
    Native->>Native: Finalize audio file
    Native->>FS: Save WAV file (16kHz, 16-bit, mono)
    Native-->>PC: File path returned
    PC-->>AudioSvc: Audio file saved
    AudioSvc-->>Cubit: Recording completed
    
    Note over User,FS: ü§ñ AI Transcription via FFI (WORKING)
    
    Cubit->>FFI: transcribeAudio(filePath)
    activate FFI
    FFI->>Whisper: Initialize model (if needed)
    FFI->>Whisper: Load & validate audio file
    Whisper->>Whisper: Read WAV samples
    
    alt Apple Silicon (M1/M2/M3)
        Whisper->>GPU: Metal GPU acceleration
        GPU->>GPU: Neural network inference
        GPU-->>Whisper: Accelerated results
        Note right of GPU: ~2-3x faster than CPU
    else Other platforms
        Whisper->>Whisper: CPU-based processing
        Note right of Whisper: Still very fast
    end
    
    Whisper->>Whisper: Generate text transcription
    Whisper-->>FFI: Return transcribed text
    deactivate FFI
    FFI-->>Cubit: Transcription completed
    
    Cubit->>FS: Save VoiceMemo with transcription
    deactivate Cubit
    Cubit-->>UI: TranscriptionCompleted state
    UI-->>User: Show transcribed text
```

## üöÄ Quick Start

### Prerequisites
- Flutter SDK 3.16.0+
- Xcode (for iOS/macOS)
- Android Studio (for Android)
- CMake (for native libraries)

### Setup
```bash
# Clone the repository
git clone <repository-url>
cd flutter_voice_bridge

# Install dependencies
flutter pub get

# Build native Whisper library
./scripts/build_whisper.sh

# Run on your platform
flutter run -d macos    # Recommended for full transcription
flutter run -d ios      # iOS Simulator
flutter run -d android  # Android
```

## üéØ Key Features Demonstrated

### **‚úÖ Working Features**
- **Audio Recording**: Full platform integration with native APIs
- **Speech-to-Text**: Offline transcription with 147MB Whisper model
- **GPU Acceleration**: Metal GPU support on Apple Silicon
- **Clean Architecture**: Production-ready code organization
- **State Management**: BLoC pattern with immutable states
- **Error Handling**: Comprehensive error recovery
- **Memory Management**: Proper FFI resource cleanup
- **Platform Views**: Native UI components in Flutter

### **üîß Technical Achievements**
- **Platform Channels**: Bidirectional Flutter ‚Üî Native communication
- **Dart FFI**: Direct C++ library integration with memory safety
- **AI Integration**: Local Whisper.cpp with GPU acceleration
- **Audio Processing**: 16kHz WAV format optimized for speech recognition
- **Multi-threading**: Background transcription using isolates
- **Native Libraries**: Cross-platform C++ compilation and deployment

## üì± Platform Status

| Platform | Audio Recording | Transcription | GPU Acceleration | Status |
|----------|----------------|---------------|------------------|---------|
| **iOS** | ‚úÖ Working | ‚úÖ Working | ‚úÖ Metal | **Ready** |
| **macOS** | ‚úÖ Working | ‚úÖ Working | ‚úÖ Metal | **Ready** |
| **Android** | ‚úÖ Working | ‚ö†Ô∏è Partial | ‚ö†Ô∏è OpenGL | In Progress |

## üìö Documentation

- **[SETUP.md](./SETUP.md)** - Complete setup instructions
- **[ARCHITECTURE.md](./ARCHITECTURE.md)** - Technical architecture deep dive  
- **[FEATURE_STATUS.md](./FEATURE_STATUS.md)** - Current implementation status
- **[WHISPER_SETUP.md](./WHISPER_SETUP.md)** - AI transcription setup guide
- **[WORKSHOP_GUIDE.md](./WORKSHOP_GUIDE.md)** - Learning modules and tutorials

## üèÜ Learning Outcomes

This project demonstrates **production-grade Flutter development** including:

### **üîß Technical Skills**
- Advanced Platform Channel implementation
- Dart FFI with C++ library integration
- AI model integration and optimization
- Clean Architecture patterns
- Advanced state management
- Memory management and resource cleanup
- Performance optimization techniques

### **üèóÔ∏è Architecture Patterns**
- Clean Architecture (MVVM)
- Dependency Injection
- Repository Pattern
- Observer Pattern (BLoC)
- Factory Pattern
- Service Locator Pattern

### **üì± Platform Integration**
- Native iOS/macOS Swift development
- Native Android Kotlin development
- Cross-platform native library compilation
- GPU acceleration integration
- Audio processing and optimization

## üéØ Real-World Applications

The patterns and techniques demonstrated here are directly applicable to:

- **AI-powered mobile apps** (chatbots, voice assistants, image recognition)
- **Multimedia applications** (audio/video processing, streaming)
- **Performance-critical apps** (games, real-time processing)
- **Enterprise applications** (offline-first, native integration)
- **IoT and hardware integration** (sensor data, device communication)

## üèÖ Achievement Unlocked

‚úÖ **Offline AI Integration**: Successfully implemented local speech recognition  
‚úÖ **Platform Mastery**: Native audio integration across iOS, macOS, Android  
‚úÖ **Architecture Excellence**: Clean, maintainable, and testable codebase  
‚úÖ **Performance Optimization**: GPU-accelerated AI inference  
‚úÖ **Production Ready**: Error handling, logging, and resource management  

---

**Built with ‚ù§Ô∏è using Flutter, Dart FFI, and Whisper.cpp**

