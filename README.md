# üéôÔ∏è Flutter Voice Bridge

**Flutter Voice Bridge** is a **production-ready** cross-platform application showcasing advanced integration of native device features and local AI capabilities within a Flutter app. It provides a robust foundation for building voice-powered applications, featuring audio recording, playback, and **working offline speech-to-text transcription** using `Whisper.cpp`.

This project follows **Clean Architecture** principles and demonstrates **real-world implementation** of complex Flutter concepts including FFI, Platform Channels, and AI integration.

> **üéØ Status**: Currently **85% complete** with full iOS/macOS transcription support and comprehensive Android audio features. Perfect for learning advanced Flutter development patterns.

## ‚ú® Features

- **‚úÖ Cross-Platform Audio Recording**: High-quality audio capture on iOS, macOS, and Android with optimized formats.
- **‚úÖ Local Audio Playback**: Play recorded memos directly within the app across all platforms.
- **‚úÖ Offline Speech-to-Text**: **WORKING** on-device transcription using `Whisper.cpp` via Dart FFI. No internet connection required.
- **‚úÖ Real-time Audio Visualization**: Custom waveform, spectrum, and particle visualizations during recording.
- **‚úÖ Keyword Extraction**: Automatic keyword detection from transcribed text with intelligent filtering.
- **‚úÖ Clean Architecture (MVVM)**: A clear separation of concerns between UI, business logic, and data layers.
- **‚úÖ Dependency Injection**: Loose coupling and enhanced testability using `get_it`.
- **‚úÖ State Management with BLoC/Cubit**: Predictable and scalable state management with real-time UI updates.
- **‚úÖ Native Integration**: Deep integration with native APIs via Platform Channels and Dart FFI.
- **‚úÖ GPU Acceleration**: Metal GPU support on Apple Silicon for fast AI inference.
- **üìö Comprehensive Documentation**: Complete guides for architecture, setup, and feature implementation.

## üèõÔ∏è Project Architecture

The application is structured using a clean, layered architecture that separates concerns and promotes modularity.

- **Presentation Layer**: Flutter widgets, UI components, and state management (BLoC/Cubit).
- **Business Logic Layer**: Application logic, use cases, and state orchestration.
- **Data Layer**: Abstract repositories and data sources.
- **Platform Layer**: Native integrations (Platform Channels, FFI) and device-specific services.

For a complete technical breakdown, including diagrams and design patterns, please see the [**Architecture Deep Dive (`ARCHITECTURE.md`)**](./ARCHITECTURE.md).

For detailed feature implementation status and checklist, see [**Feature Status (`FEATURE_STATUS.md`)**](./FEATURE_STATUS.md).

## üöÄ Getting Started

‚ö†Ô∏è **Important**: This project requires Whisper AI model files (~141MB) that are **excluded from the repository** due to GitHub's 100MB file size limit. You must download them separately during setup.

### üìã Complete Setup Guide

**‚Üí See [SETUP.md](SETUP.md) for complete installation instructions including:**
- Model file download and placement
- Platform-specific dependencies
- Build scripts and troubleshooting
- Alternative model options

### Quick Setup Summary

```bash
# 1. Clone repository
git clone https://github.com/your-username/flutter_voice_bridge.git
cd flutter_voice_bridge

# 2. Download required Whisper model (141MB)
mkdir -p assets/models android/app/src/main/assets/models ios/Runner/Models macos/Runner/Models
curl -L "https://huggingface.co/ggerganov/whisper.cpp/resolve/main/ggml-base.en.bin" -o assets/models/ggml-base.en.bin
cp assets/models/ggml-base.en.bin android/app/src/main/assets/models/
cp assets/models/ggml-base.en.bin ios/Runner/Models/
cp assets/models/ggml-base.en.bin macos/Runner/Models/

# 3. Install dependencies
flutter pub get

# 4. Run the app
flutter run
```

### 1. Prerequisites

- **Flutter**: Ensure you have the Flutter SDK installed. [Installation Guide](https://flutter.dev/docs/get-started/install).
- **IDE**: Android Studio or Visual Studio Code with the Flutter plugin.
- **Platform-specific tools**:
  - **macOS/iOS**: Xcode and CocoaPods.
  - **Android**: Android SDK and NDK.
  - **Build tools**: `cmake` and `git` are required for building the native `whisper.cpp` library.

### 2. Installation

```bash
# 1. Clone the repository
git clone https://github.com/your-username/flutter_voice_bridge.git
cd flutter_voice_bridge

# 2. Install Flutter packages
flutter pub get
```

### 3. Native Dependencies Setup (Whisper.cpp)

This project includes a **working** native `Whisper.cpp` library for offline transcription. The FFI integration is already configured and functional.

**Current Status**: Model files are **not included** in git due to size limits - you must download them using the instructions in [SETUP.md](SETUP.md).

```bash
# Model files must be downloaded separately (see SETUP.md)
# Native libraries are already configured and ready to use
```

**What's Included**:
1. ‚úÖ FFI wrapper with proper memory management
2. ‚úÖ Platform-specific integration ready to use
3. ‚úÖ Build scripts for native libraries
4. ‚ö†Ô∏è Model files must be downloaded separately

**Current Support**:
- **iOS/macOS**: ‚úÖ Full transcription support (WAV format)
- **Android**: ‚ö†Ô∏è Audio recording works, transcription needs format conversion

For implementation details, see [**Feature Status (`FEATURE_STATUS.md`)**](./FEATURE_STATUS.md).

### 4. Running the App

**After downloading model files** (see [SETUP.md](SETUP.md)), the app is ready to run with full transcription capabilities on iOS/macOS.

```bash
# Run on iOS/macOS for full transcription features
flutter run -d ios
flutter run -d macos

# Run on Android for audio recording and playback
flutter run -d android
```

**üéâ First Launch**: Once model files are in place, you can immediately start recording and transcribing voice memos!

## üîß Troubleshooting

### ‚úÖ Transcription Working Status

**Current Status (July 2025)**:
- **iOS/macOS**: ‚úÖ **Transcription fully working** - WAV format compatibility fixed
- **Android**: ‚ö†Ô∏è Audio recording works, transcription needs M4A‚ÜíWAV conversion

### Android Recording Permissions

The app handles runtime audio recording permissions automatically:
1. Grant microphone permission when prompted
2. The app will guide you through any permission issues
3. Recording and playback work perfectly on Android

### iOS/macOS Transcription Success

**Fixed Issues**:
- ‚úÖ Audio format compatibility (now uses WAV instead of M4A)
- ‚úÖ Whisper model loading and extraction
- ‚úÖ FFI memory management
- ‚úÖ GPU acceleration on Apple Silicon

### Whisper Model Management

**Manual Model Setup Required**:
- ‚ö†Ô∏è Model files are not included in repository (too large for GitHub)
- üìã Follow [SETUP.md](SETUP.md) for download instructions
- ‚úÖ 147MB English model provides excellent quality
- ‚úÖ Metal GPU acceleration enabled

### Performance Optimization

**Apple Silicon Benefits**:
- üöÄ M1/M2/M3 Mac: GPU-accelerated transcription
- ‚ö° Fast inference with Metal backend
- üíæ Efficient memory usage with proper cleanup

## ü§ù Contributing

Contributions are welcome! If you have suggestions for improvements, please open an issue or submit a pull request.

**Model File Policy**: 
- Never commit model files (.bin files are gitignored)
- Document any model changes in [SETUP.md](SETUP.md)
- Include download instructions for any new dependencies

---

_This project is intended for educational purposes and as a demonstration of advanced Flutter capabilities._

